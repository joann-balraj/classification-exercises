{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf8759df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Graph\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ebd95c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = acquire.get_titanic_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4b4698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(\"passenger_id\")\n",
    "df = df.drop(columns=[\"class\", \"embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bfe2a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "848295f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"deck\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10654918",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.embark_town = df.embark_town.fillna(value=df.embark_town.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "330345e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    133\n",
       "0     44\n",
       "Name: alone, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_age_info = df[df.age.isna()]\n",
    "no_age_info.alone.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed104afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.fare.hist(), no_age_info.fare.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d0885e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived\n",
      "Population:\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: survived, dtype: float64\n",
      "No age\n",
      "0    0.706215\n",
      "1    0.293785\n",
      "Name: survived, dtype: float64\n",
      "\n",
      "\n",
      "pclass\n",
      "Population:\n",
      "3    0.551066\n",
      "1    0.242424\n",
      "2    0.206510\n",
      "Name: pclass, dtype: float64\n",
      "No age\n",
      "3    0.768362\n",
      "1    0.169492\n",
      "2    0.062147\n",
      "Name: pclass, dtype: float64\n",
      "\n",
      "\n",
      "sex\n",
      "Population:\n",
      "male      0.647587\n",
      "female    0.352413\n",
      "Name: sex, dtype: float64\n",
      "No age\n",
      "male      0.700565\n",
      "female    0.299435\n",
      "Name: sex, dtype: float64\n",
      "\n",
      "\n",
      "sibsp\n",
      "Population:\n",
      "0    0.682379\n",
      "1    0.234568\n",
      "2    0.031425\n",
      "4    0.020202\n",
      "3    0.017957\n",
      "8    0.007856\n",
      "5    0.005612\n",
      "Name: sibsp, dtype: float64\n",
      "No age\n",
      "0    0.774011\n",
      "1    0.146893\n",
      "8    0.039548\n",
      "3    0.022599\n",
      "2    0.016949\n",
      "Name: sibsp, dtype: float64\n",
      "\n",
      "\n",
      "parch\n",
      "Population:\n",
      "0    0.760943\n",
      "1    0.132435\n",
      "2    0.089787\n",
      "3    0.005612\n",
      "5    0.005612\n",
      "4    0.004489\n",
      "6    0.001122\n",
      "Name: parch, dtype: float64\n",
      "No age\n",
      "0    0.887006\n",
      "2    0.067797\n",
      "1    0.045198\n",
      "Name: parch, dtype: float64\n",
      "\n",
      "\n",
      "embark_town\n",
      "Population:\n",
      "Southampton    0.724409\n",
      "Cherbourg      0.188976\n",
      "Queenstown     0.086614\n",
      "Name: embark_town, dtype: float64\n",
      "No age\n",
      "Southampton    0.508475\n",
      "Queenstown     0.276836\n",
      "Cherbourg      0.214689\n",
      "Name: embark_town, dtype: float64\n",
      "\n",
      "\n",
      "alone\n",
      "Population:\n",
      "1    0.602694\n",
      "0    0.397306\n",
      "Name: alone, dtype: float64\n",
      "No age\n",
      "1    0.751412\n",
      "0    0.248588\n",
      "Name: alone, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in df.drop(columns=[\"age\", \"fare\"]).columns:\n",
    "    print(column)\n",
    "    print(\"Population:\")\n",
    "    print(df[column].value_counts(normalize=True))\n",
    "    print(\"No age\")\n",
    "    print(no_age_info[column].value_counts(normalize=True))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37baee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age = df.age.fillna(value=df.age.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b8be1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              survived  pclass   age  sibsp  parch     fare  alone  sex_male  \\\n",
       "passenger_id                                                                   \n",
       "0                    0       3  22.0      1      0   7.2500      0         1   \n",
       "1                    1       1  38.0      1      0  71.2833      0         0   \n",
       "2                    1       3  26.0      0      0   7.9250      1         0   \n",
       "3                    1       1  35.0      1      0  53.1000      0         0   \n",
       "4                    0       3  35.0      0      0   8.0500      1         1   \n",
       "\n",
       "              embark_town_Queenstown  embark_town_Southampton  \n",
       "passenger_id                                                   \n",
       "0                                  0                        1  \n",
       "1                                  0                        0  \n",
       "2                                  0                        1  \n",
       "3                                  0                        1  \n",
       "4                                  0                        1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time to encode the encodeable!\n",
    "dummy_df = pd.get_dummies(df[['sex','embark_town']], dummy_na=False, drop_first=[True, True])\n",
    "\n",
    "# Drop the original columns we encoded\n",
    "df = df.drop(columns=[\"sex\", \"embark_town\"])\n",
    "\n",
    "# Stitch the df and the dummy_df together again\n",
    "df = pd.concat([df, dummy_df], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26ae271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dca1a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc5b466c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "# The mode is a great baseline\n",
    "baseline = y_train.mode()\n",
    "\n",
    "# Produce a boolean array with True representing a match between the baseline prediction and reality\n",
    "matches_baseline_prediction = y_train == 0\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2ad2a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree of 1 depth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.820433</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.790217</td>\n",
       "      <td>0.797255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.863192</td>\n",
       "      <td>0.696335</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.779764</td>\n",
       "      <td>0.799197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.726776</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.784023</td>\n",
       "      <td>0.797358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.820433    0.760000  0.799197    0.790217      0.797255\n",
       "recall       0.863192    0.696335  0.799197    0.779764      0.799197\n",
       "f1-score     0.841270    0.726776  0.799197    0.784023      0.797358\n",
       "support    307.000000  191.000000  0.799197  498.000000    498.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make the model\n",
    "tree1 = DecisionTreeClassifier(max_depth=1, random_state=123)\n",
    "\n",
    "# Fit the model (on train and only train)\n",
    "tree1 = tree1.fit(X_train, y_train)\n",
    "\n",
    "# Use the model\n",
    "# We'll evaluate the model's performance on train, first\n",
    "y_predictions = tree1.predict(X_train)\n",
    "\n",
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of 1 depth\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaebe160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree with max depth of 2\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.820433    0.760000  0.799197    0.790217      0.797255\n",
      "recall       0.863192    0.696335  0.799197    0.779764      0.799197\n",
      "f1-score     0.841270    0.726776  0.799197    0.784023      0.797358\n",
      "support    307.000000  191.000000  0.799197  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 3\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 4\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.831858    0.842767  0.835341    0.837313      0.836042\n",
      "recall       0.918567    0.701571  0.835341    0.810069      0.835341\n",
      "f1-score     0.873065    0.765714  0.835341    0.819390      0.831892\n",
      "support    307.000000  191.000000  0.835341  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 5\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.852410    0.855422  0.853414    0.853916      0.853565\n",
      "recall       0.921824    0.743455  0.853414    0.832640      0.853414\n",
      "f1-score     0.885759    0.795518  0.853414    0.840639      0.851149\n",
      "support    307.000000  191.000000  0.853414  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 6\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.838983    0.930556  0.865462    0.884769      0.874104\n",
      "recall       0.967427    0.701571  0.865462    0.834499      0.865462\n",
      "f1-score     0.898638    0.800000  0.865462    0.849319      0.860807\n",
      "support    307.000000  191.000000  0.865462  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 7\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.887850    0.875706  0.883534    0.881778      0.883193\n",
      "recall       0.928339    0.811518  0.883534    0.869929      0.883534\n",
      "f1-score     0.907643    0.842391  0.883534    0.875017      0.882617\n",
      "support    307.000000  191.000000  0.883534  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 8\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.874636    0.954839  0.899598    0.914737      0.905396\n",
      "recall       0.977199    0.774869  0.899598    0.876034      0.899598\n",
      "f1-score     0.923077    0.855491  0.899598    0.889284      0.897156\n",
      "support    307.000000  191.000000  0.899598  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 9\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.905488    0.941176  0.917671    0.923332      0.919176\n",
      "recall       0.967427    0.837696  0.917671    0.902562      0.917671\n",
      "f1-score     0.935433    0.886427  0.917671    0.910930      0.916637\n",
      "support    307.000000  191.000000  0.917671  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 10\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.931250    0.949438  0.937751    0.940344      0.938226\n",
      "recall       0.970684    0.884817  0.937751    0.927750      0.937751\n",
      "f1-score     0.950558    0.915989  0.937751    0.933274      0.937300\n",
      "support    307.000000  191.000000  0.937751  498.000000    498.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 11):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    y_predictions = tree.predict(X_train)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\"Tree with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1388446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.026236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.040949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.853414</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.054348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.865462</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.075742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.883534</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.103160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.899598</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.109879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.917671</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.118605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.937751</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.152704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.955823</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.142739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>0.971888</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.149458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.981928</td>\n",
       "      <td>0.827103</td>\n",
       "      <td>0.154825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>0.989960</td>\n",
       "      <td>0.817757</td>\n",
       "      <td>0.172203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  train_accuracy  validate_accuracy  difference\n",
       "0           2        0.799197           0.761682    0.037515\n",
       "1           3        0.825301           0.799065    0.026236\n",
       "2           4        0.835341           0.794393    0.040949\n",
       "3           5        0.853414           0.799065    0.054348\n",
       "4           6        0.865462           0.789720    0.075742\n",
       "5           7        0.883534           0.780374    0.103160\n",
       "6           8        0.899598           0.789720    0.109879\n",
       "7           9        0.917671           0.799065    0.118605\n",
       "8          10        0.937751           0.785047    0.152704\n",
       "9          11        0.955823           0.813084    0.142739\n",
       "10         12        0.971888           0.822430    0.149458\n",
       "11         13        0.981928           0.827103    0.154825\n",
       "12         14        0.989960           0.817757    0.172203\n",
       "13         15        0.993976           0.813084    0.180892\n",
       "14         16        0.993976           0.813084    0.180892\n",
       "15         17        0.993976           0.813084    0.180892\n",
       "16         18        0.993976           0.813084    0.180892\n",
       "17         19        0.993976           0.813084    0.180892\n",
       "18         20        0.993976           0.813084    0.180892\n",
       "19         21        0.993976           0.813084    0.180892\n",
       "20         22        0.993976           0.813084    0.180892\n",
       "21         23        0.993976           0.813084    0.180892\n",
       "22         24        0.993976           0.813084    0.180892"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "for i in range(2, 25):\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    in_sample_accuracy = tree.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = tree.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1711e220",
   "metadata": {},
   "source": [
    "# Decision Tree Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c50f9a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Graph\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a5751ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = acquire.get_titanic_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1824ba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(\"passenger_id\")\n",
    "df = df.drop(columns=[\"class\", \"embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63938af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            177\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "deck           688\n",
       "embark_town      2\n",
       "alone            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc5b4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"deck\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb13a03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.embark_town = df.embark_town.fillna(value=df.embark_town.mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4029368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    133\n",
       "0     44\n",
       "Name: alone, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_age_info = df[df.age.isna()]\n",
    "no_age_info.alone.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c8a7598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived\n",
      "Population:\n",
      "0    0.616162\n",
      "1    0.383838\n",
      "Name: survived, dtype: float64\n",
      "No age\n",
      "0    0.706215\n",
      "1    0.293785\n",
      "Name: survived, dtype: float64\n",
      "----------------------------------\n",
      "pclass\n",
      "Population:\n",
      "3    0.551066\n",
      "1    0.242424\n",
      "2    0.206510\n",
      "Name: pclass, dtype: float64\n",
      "No age\n",
      "3    0.768362\n",
      "1    0.169492\n",
      "2    0.062147\n",
      "Name: pclass, dtype: float64\n",
      "----------------------------------\n",
      "sex\n",
      "Population:\n",
      "male      0.647587\n",
      "female    0.352413\n",
      "Name: sex, dtype: float64\n",
      "No age\n",
      "male      0.700565\n",
      "female    0.299435\n",
      "Name: sex, dtype: float64\n",
      "----------------------------------\n",
      "sibsp\n",
      "Population:\n",
      "0    0.682379\n",
      "1    0.234568\n",
      "2    0.031425\n",
      "4    0.020202\n",
      "3    0.017957\n",
      "8    0.007856\n",
      "5    0.005612\n",
      "Name: sibsp, dtype: float64\n",
      "No age\n",
      "0    0.774011\n",
      "1    0.146893\n",
      "8    0.039548\n",
      "3    0.022599\n",
      "2    0.016949\n",
      "Name: sibsp, dtype: float64\n",
      "----------------------------------\n",
      "parch\n",
      "Population:\n",
      "0    0.760943\n",
      "1    0.132435\n",
      "2    0.089787\n",
      "3    0.005612\n",
      "5    0.005612\n",
      "4    0.004489\n",
      "6    0.001122\n",
      "Name: parch, dtype: float64\n",
      "No age\n",
      "0    0.887006\n",
      "2    0.067797\n",
      "1    0.045198\n",
      "Name: parch, dtype: float64\n",
      "----------------------------------\n",
      "embark_town\n",
      "Population:\n",
      "Southampton    0.724409\n",
      "Cherbourg      0.188976\n",
      "Queenstown     0.086614\n",
      "Name: embark_town, dtype: float64\n",
      "No age\n",
      "Southampton    0.508475\n",
      "Queenstown     0.276836\n",
      "Cherbourg      0.214689\n",
      "Name: embark_town, dtype: float64\n",
      "----------------------------------\n",
      "alone\n",
      "Population:\n",
      "1    0.602694\n",
      "0    0.397306\n",
      "Name: alone, dtype: float64\n",
      "No age\n",
      "1    0.751412\n",
      "0    0.248588\n",
      "Name: alone, dtype: float64\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "for column in df.drop(columns=[\"age\", \"fare\"]).columns:\n",
    "    print(column)\n",
    "    print(\"Population:\")\n",
    "    print(df[column].value_counts(normalize=True))\n",
    "    print(\"No age\")\n",
    "    print(no_age_info[column].value_counts(normalize=True))\n",
    "    print('----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec23d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age = df.age.fillna(value=df.age.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86ef3452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              survived  pclass   age  sibsp  parch     fare  alone  sex_male  \\\n",
       "passenger_id                                                                   \n",
       "0                    0       3  22.0      1      0   7.2500      0         1   \n",
       "1                    1       1  38.0      1      0  71.2833      0         0   \n",
       "2                    1       3  26.0      0      0   7.9250      1         0   \n",
       "3                    1       1  35.0      1      0  53.1000      0         0   \n",
       "4                    0       3  35.0      0      0   8.0500      1         1   \n",
       "\n",
       "              embark_town_Queenstown  embark_town_Southampton  \n",
       "passenger_id                                                   \n",
       "0                                  0                        1  \n",
       "1                                  0                        0  \n",
       "2                                  0                        1  \n",
       "3                                  0                        1  \n",
       "4                                  0                        1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_df = pd.get_dummies(df[['sex','embark_town']], dummy_na=False, drop_first=[True, True])\n",
    "\n",
    "df = df.drop(columns=[\"sex\", \"embark_town\"])\n",
    "\n",
    "df = pd.concat([df, dummy_df], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d372664",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=.2, random_state=123, stratify=df.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)\n",
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49d1d399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "baseline = y_train.mode()\n",
    "\n",
    "matches_baseline_prediction = y_train == 0\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6544eb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree of 1 depth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.773481</td>\n",
       "      <td>0.801471</td>\n",
       "      <td>0.781124</td>\n",
       "      <td>0.787476</td>\n",
       "      <td>0.784216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.912052</td>\n",
       "      <td>0.570681</td>\n",
       "      <td>0.781124</td>\n",
       "      <td>0.741366</td>\n",
       "      <td>0.781124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.837070</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.781124</td>\n",
       "      <td>0.751868</td>\n",
       "      <td>0.771715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.781124</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.773481    0.801471  0.781124    0.787476      0.784216\n",
       "recall       0.912052    0.570681  0.781124    0.741366      0.781124\n",
       "f1-score     0.837070    0.666667  0.781124    0.751868      0.771715\n",
       "support    307.000000  191.000000  0.781124  498.000000    498.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest1 = RandomForestClassifier(max_depth=1, random_state=123)\n",
    "\n",
    "tree1 = forest1.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_predictions = forest1.predict(X_train)\n",
    "\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of 1 depth\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44f88362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree with max depth of 2\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.815029    0.835526  0.821285    0.825278      0.822890\n",
      "recall       0.918567    0.664921  0.821285    0.791744      0.821285\n",
      "f1-score     0.863706    0.740525  0.821285    0.802115      0.816462\n",
      "support    307.000000  191.000000  0.821285  498.000000    498.000000\n",
      "-------------------------------------------------------------------------------\n",
      "Tree with max depth of 3\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.836257    0.865385  0.845382    0.850821      0.847429\n",
      "recall       0.931596    0.706806  0.845382    0.819201      0.845382\n",
      "f1-score     0.881356    0.778098  0.845382    0.829727      0.841753\n",
      "support    307.000000  191.000000  0.845382  498.000000    498.000000\n",
      "-------------------------------------------------------------------------------\n",
      "Tree with max depth of 4\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.842566    0.883871  0.855422    0.863218      0.858408\n",
      "recall       0.941368    0.717277  0.855422    0.829323      0.855422\n",
      "f1-score     0.889231    0.791908  0.855422    0.840569      0.851904\n",
      "support    307.000000  191.000000  0.855422  498.000000    498.000000\n",
      "-------------------------------------------------------------------------------\n",
      "Tree with max depth of 5\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.846821    0.907895  0.865462    0.877358      0.870245\n",
      "recall       0.954397    0.722513  0.865462    0.838455      0.865462\n",
      "f1-score     0.897397    0.804665  0.865462    0.851031      0.861831\n",
      "support    307.000000  191.000000  0.865462  498.000000    498.000000\n",
      "-------------------------------------------------------------------------------\n",
      "Tree with max depth of 6\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.866667    0.947712  0.891566    0.907190      0.897750\n",
      "recall       0.973941    0.759162  0.891566    0.866552      0.891566\n",
      "f1-score     0.917178    0.843023  0.891566    0.880101      0.888737\n",
      "support    307.000000  191.000000  0.891566  498.000000    498.000000\n",
      "-------------------------------------------------------------------------------\n",
      "Tree with max depth of 7\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.906907    0.969697  0.927711    0.938302      0.930989\n",
      "recall       0.983713    0.837696  0.927711    0.910705      0.927711\n",
      "f1-score     0.943750    0.898876  0.927711    0.921313      0.926539\n",
      "support    307.000000  191.000000  0.927711  498.000000    498.000000\n",
      "-------------------------------------------------------------------------------\n",
      "Tree with max depth of 8\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.926829    0.982353  0.945783    0.954591      0.948124\n",
      "recall       0.990228    0.874346  0.945783    0.932287      0.945783\n",
      "f1-score     0.957480    0.925208  0.945783    0.941344      0.945103\n",
      "support    307.000000  191.000000  0.945783  498.000000    498.000000\n",
      "-------------------------------------------------------------------------------\n",
      "Tree with max depth of 9\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.938650    0.994186  0.957831    0.966418      0.959950\n",
      "recall       0.996743    0.895288  0.957831    0.946015      0.957831\n",
      "f1-score     0.966825    0.942149  0.957831    0.954487      0.957361\n",
      "support    307.000000  191.000000  0.957831  498.000000    498.000000\n",
      "-------------------------------------------------------------------------------\n",
      "Tree with max depth of 10\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.953416    1.000000   0.96988    0.976708      0.971283\n",
      "recall       1.000000    0.921466   0.96988    0.960733      0.969880\n",
      "f1-score     0.976153    0.959128   0.96988    0.967640      0.969623\n",
      "support    307.000000  191.000000   0.96988  498.000000    498.000000\n",
      "-------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 11):\n",
    "    forest = RandomForestClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    y_predictions = forest.predict(X_train)\n",
    "\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\"Tree with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print('-------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ce2965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "\n",
    "for i in range(2, 25):\n",
    "    forest = RandomForestClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3553ebbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>0.050257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.845382</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.050989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.855422</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.056356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.865462</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.061724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.078482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.105281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.945783</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.137372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.957831</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.154093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.969880</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.156795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.977912</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.169500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>0.983936</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.170852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.188886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.185565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.185565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.180892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.185565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.185565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.185565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.185565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.185565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.185565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>0.993976</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.185565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  train_accuracy  validate_accuracy  difference\n",
       "0           2        0.821285           0.771028    0.050257\n",
       "1           3        0.845382           0.794393    0.050989\n",
       "2           4        0.855422           0.799065    0.056356\n",
       "3           5        0.865462           0.803738    0.061724\n",
       "4           6        0.891566           0.813084    0.078482\n",
       "5           7        0.927711           0.822430    0.105281\n",
       "6           8        0.945783           0.808411    0.137372\n",
       "7           9        0.957831           0.803738    0.154093\n",
       "8          10        0.969880           0.813084    0.156795\n",
       "9          11        0.977912           0.808411    0.169500\n",
       "10         12        0.983936           0.813084    0.170852\n",
       "11         13        0.987952           0.799065    0.188886\n",
       "12         14        0.993976           0.813084    0.180892\n",
       "13         15        0.993976           0.808411    0.185565\n",
       "14         16        0.993976           0.808411    0.185565\n",
       "15         17        0.993976           0.813084    0.180892\n",
       "16         18        0.993976           0.808411    0.185565\n",
       "17         19        0.993976           0.808411    0.185565\n",
       "18         20        0.993976           0.808411    0.185565\n",
       "19         21        0.993976           0.808411    0.185565\n",
       "20         22        0.993976           0.808411    0.185565\n",
       "21         23        0.993976           0.808411    0.185565\n",
       "22         24        0.993976           0.808411    0.185565"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66c3e66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>0.050257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.845382</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.050989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.855422</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.056356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.865462</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.061724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.078482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  train_accuracy  validate_accuracy  difference\n",
       "0          2        0.821285           0.771028    0.050257\n",
       "1          3        0.845382           0.794393    0.050989\n",
       "2          4        0.855422           0.799065    0.056356\n",
       "3          5        0.865462           0.803738    0.061724\n",
       "4          6        0.891566           0.813084    0.078482"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.10\n",
    "\n",
    "models = []\n",
    "metrics = []\n",
    "\n",
    "for i in range(2, 25):\n",
    "    forest = RandomForestClassifier(max_depth=i, min_samples_leaf=1, random_state=123)\n",
    "\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)   \n",
    "    out_of_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "\n",
    "    difference = in_sample_accuracy - out_of_sample_accuracy\n",
    "    \n",
    "    if difference > threshold:\n",
    "        break\n",
    "    \n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy,\n",
    "        \"difference\": difference\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "    models.append(forest)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "500dd5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_samples_per_leaf</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.925703</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.103273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0.901606</td>\n",
       "      <td>0.817757</td>\n",
       "      <td>0.083849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.887550</td>\n",
       "      <td>0.817757</td>\n",
       "      <td>0.069793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.877510</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.097136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0.871486</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.072421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0.869478</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.079758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.865462</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.071069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>0.857430</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.063037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.857430</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.072383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.849398</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.064351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>0.839357</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.058984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0.839357</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.058984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.048287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.041606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.831325</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.041606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.827309</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.046935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.038866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.781124</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.019442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    min_samples_per_leaf  max_depth  train_accuracy  validate_accuracy  \\\n",
       "0                      2         18        0.925703           0.822430   \n",
       "1                      3         17        0.901606           0.817757   \n",
       "2                      4         16        0.887550           0.817757   \n",
       "3                      5         15        0.877510           0.780374   \n",
       "4                      6         14        0.871486           0.799065   \n",
       "5                      7         13        0.869478           0.789720   \n",
       "6                      8         12        0.865462           0.794393   \n",
       "7                      9         11        0.857430           0.794393   \n",
       "8                     10         10        0.857430           0.785047   \n",
       "9                     11          9        0.849398           0.785047   \n",
       "10                    12          8        0.839357           0.780374   \n",
       "11                    13          7        0.839357           0.780374   \n",
       "12                    14          6        0.833333           0.785047   \n",
       "13                    15          5        0.831325           0.789720   \n",
       "14                    16          4        0.831325           0.789720   \n",
       "15                    17          3        0.827309           0.780374   \n",
       "16                    18          2        0.805221           0.766355   \n",
       "17                    19          1        0.781124           0.761682   \n",
       "\n",
       "    difference  \n",
       "0     0.103273  \n",
       "1     0.083849  \n",
       "2     0.069793  \n",
       "3     0.097136  \n",
       "4     0.072421  \n",
       "5     0.079758  \n",
       "6     0.071069  \n",
       "7     0.063037  \n",
       "8     0.072383  \n",
       "9     0.064351  \n",
       "10    0.058984  \n",
       "11    0.058984  \n",
       "12    0.048287  \n",
       "13    0.041606  \n",
       "14    0.041606  \n",
       "15    0.046935  \n",
       "16    0.038866  \n",
       "17    0.019442  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = []\n",
    "max_depth = 20\n",
    "\n",
    "for i in range(2, max_depth):\n",
    "    depth = max_depth - i\n",
    "    n_samples = i\n",
    "    forest = RandomForestClassifier(max_depth=depth, min_samples_leaf=n_samples, random_state=123)\n",
    "\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"min_samples_per_leaf\": n_samples,\n",
    "        \"max_depth\": depth,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4327698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_samples_per_leaf</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>0.050257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.845382</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.060335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.847390</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.052997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.859438</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.060372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.861446</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.062380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.863454</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.073734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.863454</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.073734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.855422</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.061029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.857430</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.072383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.849398</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.064351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.839357</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.058984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.839357</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.058984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.054968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.045622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.050295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.044927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.033574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.059640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    min_samples_per_leaf  max_depth  train_accuracy  validate_accuracy  \\\n",
       "0                      2          2        0.821285           0.771028   \n",
       "1                      3          3        0.845382           0.785047   \n",
       "2                      4          4        0.847390           0.794393   \n",
       "3                      5          5        0.859438           0.799065   \n",
       "4                      6          6        0.861446           0.799065   \n",
       "5                      7          7        0.863454           0.789720   \n",
       "6                      8          8        0.863454           0.789720   \n",
       "7                      9          9        0.855422           0.794393   \n",
       "8                     10         10        0.857430           0.785047   \n",
       "9                     11         11        0.849398           0.785047   \n",
       "10                    12         12        0.839357           0.780374   \n",
       "11                    13         13        0.839357           0.780374   \n",
       "12                    14         14        0.835341           0.780374   \n",
       "13                    15         15        0.835341           0.789720   \n",
       "14                    16         16        0.835341           0.785047   \n",
       "15                    17         17        0.825301           0.780374   \n",
       "16                    18         18        0.823293           0.789720   \n",
       "17                    19         19        0.835341           0.775701   \n",
       "\n",
       "    difference  \n",
       "0     0.050257  \n",
       "1     0.060335  \n",
       "2     0.052997  \n",
       "3     0.060372  \n",
       "4     0.062380  \n",
       "5     0.073734  \n",
       "6     0.073734  \n",
       "7     0.061029  \n",
       "8     0.072383  \n",
       "9     0.064351  \n",
       "10    0.058984  \n",
       "11    0.058984  \n",
       "12    0.054968  \n",
       "13    0.045622  \n",
       "14    0.050295  \n",
       "15    0.044927  \n",
       "16    0.033574  \n",
       "17    0.059640  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = []\n",
    "max_depth = 20\n",
    "\n",
    "for i in range(2, max_depth):\n",
    "    # Make the model\n",
    "    depth = i\n",
    "    n_samples = i\n",
    "    forest = RandomForestClassifier(max_depth=depth, min_samples_leaf=n_samples, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"min_samples_per_leaf\": n_samples,\n",
    "        \"max_depth\": depth,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f3f4422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_samples_per_leaf</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.099257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.899598</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.091187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.887550</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.074466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.877510</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.083118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.871486</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.072421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.869478</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.079758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0.867470</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.073077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.857430</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.063037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.857430</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.072383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.849398</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.064351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0.839357</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.058984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0.839357</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.058984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.054968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.045622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.050295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.044927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.789720</td>\n",
       "      <td>0.033574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.059640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.071651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>0.815261</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.030214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.780374</td>\n",
       "      <td>0.038903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.054930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.052922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.040874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.045547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.043539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.040874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.045547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.813253</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.056244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>0.811245</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.054236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.038866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>33</td>\n",
       "      <td>10</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.050220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.050220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.050220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.040874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>0.809237</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.042882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>0.809237</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.042882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.040874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.040874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>42</td>\n",
       "      <td>10</td>\n",
       "      <td>0.801205</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.034850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>0.805221</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.043539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.042187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>0.801205</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>0.034850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.026123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.026123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>0.781124</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.024115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>49</td>\n",
       "      <td>10</td>\n",
       "      <td>0.781124</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.024115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    min_samples_per_leaf  max_depth  train_accuracy  validate_accuracy  \\\n",
       "0                      2         10        0.921687           0.822430   \n",
       "1                      3         10        0.899598           0.808411   \n",
       "2                      4         10        0.887550           0.813084   \n",
       "3                      5         10        0.877510           0.794393   \n",
       "4                      6         10        0.871486           0.799065   \n",
       "5                      7         10        0.869478           0.789720   \n",
       "6                      8         10        0.867470           0.794393   \n",
       "7                      9         10        0.857430           0.794393   \n",
       "8                     10         10        0.857430           0.785047   \n",
       "9                     11         10        0.849398           0.785047   \n",
       "10                    12         10        0.839357           0.780374   \n",
       "11                    13         10        0.839357           0.780374   \n",
       "12                    14         10        0.835341           0.780374   \n",
       "13                    15         10        0.835341           0.789720   \n",
       "14                    16         10        0.835341           0.785047   \n",
       "15                    17         10        0.825301           0.780374   \n",
       "16                    18         10        0.823293           0.789720   \n",
       "17                    19         10        0.835341           0.775701   \n",
       "18                    20         10        0.833333           0.761682   \n",
       "19                    21         10        0.815261           0.785047   \n",
       "20                    22         10        0.819277           0.780374   \n",
       "21                    23         10        0.821285           0.766355   \n",
       "22                    24         10        0.819277           0.766355   \n",
       "23                    25         10        0.807229           0.766355   \n",
       "24                    26         10        0.807229           0.761682   \n",
       "25                    27         10        0.805221           0.761682   \n",
       "26                    28         10        0.807229           0.766355   \n",
       "27                    29         10        0.807229           0.761682   \n",
       "28                    30         10        0.813253           0.757009   \n",
       "29                    31         10        0.811245           0.757009   \n",
       "30                    32         10        0.805221           0.766355   \n",
       "31                    33         10        0.799197           0.761682   \n",
       "32                    34         10        0.807229           0.757009   \n",
       "33                    35         10        0.807229           0.757009   \n",
       "34                    36         10        0.807229           0.757009   \n",
       "35                    37         10        0.807229           0.766355   \n",
       "36                    38         10        0.809237           0.766355   \n",
       "37                    39         10        0.809237           0.766355   \n",
       "38                    40         10        0.807229           0.766355   \n",
       "39                    41         10        0.807229           0.766355   \n",
       "40                    42         10        0.801205           0.766355   \n",
       "41                    43         10        0.805221           0.761682   \n",
       "42                    44         10        0.799197           0.757009   \n",
       "43                    45         10        0.801205           0.766355   \n",
       "44                    46         10        0.783133           0.757009   \n",
       "45                    47         10        0.783133           0.757009   \n",
       "46                    48         10        0.781124           0.757009   \n",
       "47                    49         10        0.781124           0.757009   \n",
       "\n",
       "    difference  \n",
       "0     0.099257  \n",
       "1     0.091187  \n",
       "2     0.074466  \n",
       "3     0.083118  \n",
       "4     0.072421  \n",
       "5     0.079758  \n",
       "6     0.073077  \n",
       "7     0.063037  \n",
       "8     0.072383  \n",
       "9     0.064351  \n",
       "10    0.058984  \n",
       "11    0.058984  \n",
       "12    0.054968  \n",
       "13    0.045622  \n",
       "14    0.050295  \n",
       "15    0.044927  \n",
       "16    0.033574  \n",
       "17    0.059640  \n",
       "18    0.071651  \n",
       "19    0.030214  \n",
       "20    0.038903  \n",
       "21    0.054930  \n",
       "22    0.052922  \n",
       "23    0.040874  \n",
       "24    0.045547  \n",
       "25    0.043539  \n",
       "26    0.040874  \n",
       "27    0.045547  \n",
       "28    0.056244  \n",
       "29    0.054236  \n",
       "30    0.038866  \n",
       "31    0.037515  \n",
       "32    0.050220  \n",
       "33    0.050220  \n",
       "34    0.050220  \n",
       "35    0.040874  \n",
       "36    0.042882  \n",
       "37    0.042882  \n",
       "38    0.040874  \n",
       "39    0.040874  \n",
       "40    0.034850  \n",
       "41    0.043539  \n",
       "42    0.042187  \n",
       "43    0.034850  \n",
       "44    0.026123  \n",
       "45    0.026123  \n",
       "46    0.024115  \n",
       "47    0.024115  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = []\n",
    "max_depth = 50\n",
    "\n",
    "for i in range(2, max_depth):\n",
    "    depth = 10\n",
    "    n_samples = i\n",
    "    forest = RandomForestClassifier(max_depth=depth, min_samples_leaf=n_samples, random_state=123)\n",
    "\n",
    "    forest = forest.fit(X_train, y_train)\n",
    "\n",
    "    in_sample_accuracy = forest.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = forest.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"min_samples_per_leaf\": n_samples,\n",
    "        \"max_depth\": depth,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd0b64057e63add2b45b1ffc7eab9b09c8889b419c878e2fdf0d08f837f0fc857a7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
